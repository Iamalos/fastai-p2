{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d72a4fb-fc56-4cf3-b00d-1e66ae2546d2",
   "metadata": {},
   "source": [
    "# The forward and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca279a34-43f5-4cf9-a117-28468a52d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, matplotlib.pyplot as plt, numpy as np\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from fastcore.test import test_close\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acf6d1-e8d9-45c2-b461-31fa456330cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "path_gz = path/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz) as f: (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding=\"latin-1\")\n",
    "\n",
    "# cast numpy arrays to torch tensors\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2088c4-7841-4d84-a34e-e164521f59be",
   "metadata": {},
   "source": [
    "# Foundations version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4883d0a-6149-467e-a263-8be7e64dbd27",
   "metadata": {},
   "source": [
    "## Basic architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17ffce-5d90-45e7-b6ef-9146dc8f927c",
   "metadata": {},
   "source": [
    "We have 50 000 images each consisting of 784 pixels of 10 digits (from 0 to 9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b615d58-cf83-4754-bf81-e37538bf463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape # examples, image_length\n",
    "c = y_train.max() + 1 # num of classes\n",
    "n,m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f04ac-af08-4bb9-9fc1-cfcbd1b56897",
   "metadata": {},
   "source": [
    "We set number of hidden units at 50 and initialize weights and biases for two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405acaf3-b0bd-4dd3-8b01-a0abd2c86b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden layers\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0501014-9b71-4f24-8243-96a097c5349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0a801-537b-4ff3-93f6-8af5b50c4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b): return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986233a-c6e3-4604-9adf-1c08a044590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 50])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lin(x_valid, w1, b1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2b19c-ec94-4507-aa47-362ba913fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89d476-65bb-4084-bf93-14126a3e98f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00, 11.87,  0.00,  ...,  5.48,  2.14, 15.30],\n",
       "        [ 5.38, 10.21,  0.00,  ...,  0.88,  0.08, 20.23],\n",
       "        [ 3.31,  0.12,  3.10,  ..., 16.89,  0.00, 24.74],\n",
       "        ...,\n",
       "        [ 4.01, 10.35,  0.00,  ...,  0.23,  0.00, 18.28],\n",
       "        [10.62,  0.00, 10.72,  ...,  0.00,  0.00, 18.23],\n",
       "        [ 2.84,  0.00,  1.43,  ...,  0.00,  5.75,  2.12]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b369d5-8255-4187-a283-65363c6ace84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(t[0].reshape(5,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9ecbf-42f2-46ce-af77-5e2bfc0d2ae7",
   "metadata": {},
   "source": [
    "We can combine the above functions in a simple method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09553d6-8de5-4d94-8d61-a9226921519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    return lin(l2, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa8e18-cccb-4d3e-8c9b-ea621890d582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(x_valid)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89576def-b3fc-4eda-a8f4-f43ab954f5b9",
   "metadata": {},
   "source": [
    "Note that our final layers has a singe output which means that we cannot use the usual cross-entropy loss. For the sake of simplicity and demonstration we will use MSE loss and treat the final output as representing the particular digit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224e00e-6dd2-47b2-a619-5abc49b334ee",
   "metadata": {},
   "source": [
    "## Loss function: MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b464cb-070c-4b20-ab0e-a02ca819610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 1]), torch.Size([10000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c935b-f94b-4fea-b75c-d95d4d15fd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res-y_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d4571-0dbd-4e3d-ac5b-b3fca7ba6f1a",
   "metadata": {},
   "source": [
    "We can't simply subtract `res` from `y_valid` as due to the broadcasting rules we will get back (1000,1000) array! We need to remove the trailing unit dimension from `res`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e10d3-b2ee-403c-9dda-08705c0d4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res.squeeze(-1)-y_valid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf700c-68bc-42b0-84e0-fa88a11036c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_valid = y_train.float(), y_valid.float()\n",
    "\n",
    "preds = model(x_train)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3b85b-279e-4490-bfe1-ca7ec26f8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ): return ((output.squeeze()-targ)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc57ecc-f2ef-496e-8f7c-d4f55d62bb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4308.76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7a25f-155b-4284-be08-db135888ed4d",
   "metadata": {},
   "source": [
    "## Gradients and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52329e17-64f5-43dd-9082-cfd36700e128",
   "metadata": {},
   "source": [
    "pytorch has a built-in automatic differentiation engine and we don't need to worry about calculating derivatives by hand. If you forget a particular derivative, you can use `sumpy` to remind yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f1451-fa48-43e6-bc12-283380a33d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 x$"
      ],
      "text/plain": [
       "2*x"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import symbols, diff, sin\n",
    "x,y = symbols('x y')\n",
    "diff(x**2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f197ce5-0511-4a48-b669-d3a1556a05fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 6 x \\cos{\\left(3 x^{2} + 9 \\right)}$"
      ],
      "text/plain": [
       "6*x*cos(3*x**2 + 9)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(sin(3*x**2+9), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234678d-7e9c-4d06-a927-2fcf0ff41a4a",
   "metadata": {},
   "source": [
    "Below we caluclate the gradients by hand as a useful exercise. Note, that as our loss is a single number (a scalar), the shape of all our gradients of loss w.r.t a varaible will be the same shape as the variable itself. We will use this fact extensively to arrange the shapes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa519f-fdd6-48d8-98f4-cfd9331db591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul w.r.t input\n",
    "    inp.g = out.g @ w.T\n",
    "    w.g = inp.T @ out.g # 784, 50\n",
    "    b.g = out.g.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2f898-cc4a-4501-a9a1-ab0e27d7bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass\n",
    "    l1 = lin(inp, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w2, b2)\n",
    "    diff = out.squeeze(-1) - targ\n",
    "    loss = (diff**2).mean()\n",
    "    \n",
    "    # backward pass\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    out.g = 2 * diff[:, None] / diff.shape[0] # dout\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    l1.g = l2.g * (l1>0).float()\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576573f2-4a45-4bc1-8925-10fee64e1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3ed49-c9e8-4ac2-89b4-5a4ffaf50603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check our results\n",
    "def get_grad(x): return x.g.clone()\n",
    "chks = w1, w2, b1, b2, x_train\n",
    "grads = w1g, w2g, b1g, b2g, ig = tuple(map(get_grad, chks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cd48c-2761-480e-860f-ca5edd1dcca2",
   "metadata": {},
   "source": [
    "We can check our manually calculated gradients against pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f36970-a7c8-4aef-b62a-fe55f7511247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkgrad(x): return x.clone().requires_grad_(True)\n",
    "ptgrads = w1pt, w2pt, b1pt, b2pt, x_trainpt = tuple(map(mkgrad, chks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2522b4-183d-4454-9358-3df5d55e5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    # forward pass\n",
    "    l1 = lin(inp, w1pt, b1pt)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w2pt, b2pt)\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82784179-c808-45dc-bd21-e777f975d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(x_trainpt, y_train)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931e74fd-5725-486c-9a70-de624ea88b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4308.76, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda172e-f179-4d0f-90cb-10990ce133a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(grads, ptgrads): test_close(a, b.grad, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d392d73-8dbe-4076-8812-17c699a5d790",
   "metadata": {},
   "source": [
    "## Refactor model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69446bcf-9e2f-4fb9-9b43-57fdfd13bae4",
   "metadata": {},
   "source": [
    "### Layers as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f9f9d-b6eb-4eef-b717-ee2b0f4e68dd",
   "metadata": {},
   "source": [
    "The above approach works but is a bit clunky and not flexible. We can refactor it using layers as classes. Note that for each layer we create the `inp` and `out` variables that are used during the backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3be7a4-29c0-4ca9-8641-36e89b3ab459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.)\n",
    "        return self.out\n",
    "    def backward(self):\n",
    "        # the gradient flows backwards through the calculation graph\n",
    "        self.inp.g = self.out.g * (self.inp>0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32568e4f-8427-447f-a206-c07e5c12a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin:\n",
    "    def __init__(self, w, b): self.w, self.b = w, b\n",
    "    \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = lin(inp, self.w, self.b)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.T\n",
    "        self.w.g = self.inp.T @ self.out.g \n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea4e57f-f53a-49c7-a15f-661335c31336",
   "metadata": {},
   "source": [
    "Using ipdb tool we can check the shapes in the Mse backward function: `self.inp` is [5000, 1] while self.targ is [5000]. To avoid broadcasting the subtraction operation to [5000, 5000] we first squeeze the last dimension of `self.inp` and then unsueeze it back after the subtraction oepration.\n",
    "\n",
    "![alt text](Screenshot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe39ff-70a1-4b7b-b1cd-91e5d0d348d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse:\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp, self.targ = inp, targ\n",
    "        self.out = mse(inp, targ)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2.0 * ((self.inp.squeeze() - self.targ)).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d08dc-563a-4069-bc2c-69dbe5651cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for layer in self.layers: x = layer(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        self.loss.backward()\n",
    "        for layer in self.layers[::-1]: layer.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774f87a-6086-43d7-a292-5bd0fdee4448",
   "metadata": {},
   "source": [
    "Let's test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257956e-0c05-464f-b3ec-286059a862e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73ea4a-5913-43ef-a3c2-5170fc971b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4308.76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(x_train, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a8be9-ff9c-487d-9281-99b851a18542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb613b-a54e-4467-933b-50ecef07f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf8d635-800e-48ac-b119-ba7e31a48714",
   "metadata": {},
   "source": [
    "### Module.forward() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4892091-4290-44f9-9ade-b5718dad82a4",
   "metadata": {},
   "source": [
    "We have a lot of code repetion here: each class initializes `inp`, `out`, and calls `forward` anb `backward` methods. We can incapsulate that functonality inside separate class Module and inherit from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2984f5-a194-4384-8ccf-aa016e637328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)\n",
    "    def bwd(self): raise Exception('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978d649-7203-47a4-80be-71c2a609a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp): \n",
    "        \n",
    "        return inp.clamp_min(0.)\n",
    "    def bwd(self, out, inp): inp.g = out.g * (inp > 0.0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ed20e-6db5-4206-aeac-73de4c5cfd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): self.w, self.b = w, b\n",
    "    def forward(self, inp): return inp @ self.w + self.b\n",
    "    def bwd(self, out, inp): \n",
    "        inp.g = out.g @ self.w.T\n",
    "        self.w.g = inp.T @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db27a27-f5eb-4d2a-9edf-f5edadf785f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward(self, inp, targ): return ((inp.squeeze() - targ)**2).mean()\n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2 * (inp.squeeze() - targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabdbe9-cd19-4556-935c-e2a9fb9207da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f610a-67a1-4ba4-b7dd-0abc8e9bd8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4308.76)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(x_train, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2995689-4ec6-4aa0-9a04-125acd8f89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34bd1f-2207-4923-b613-2a9c1d6f5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994dc5-bf17-4f6d-bb15-7261166066c3",
   "metadata": {},
   "source": [
    "### Autograd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac1b0b-ca7e-41c7-a277-aed90855c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bc710-744f-41cd-918d-b27f03d5c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn((n_in, n_out)).requires_grad_()\n",
    "        self.b = torch.zeros(n_out).requires_grad_()\n",
    "    \n",
    "    def forward(self, inp): return inp @ self.w + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33bb9d-cc62-43f8-8fb1-cd06a1e65e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in,nh), nn.ReLU(), Linear(nh, n_out)]\n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return F.mse_loss(x, targ[:, None]) # add single dimension to targ for broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8c18e-029a-4c93-bac3-9b4a427e1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)\n",
    "loss = model(x_train, y_train)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3d3ca-ef92-4eb1-90af-fe76cdb633ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -31.94,  -12.18,  -64.23,   -8.61,   -5.96,   97.20,  -12.61,  -89.79,  -58.79, -106.23,  -13.70,  191.93,  -16.12,\n",
       "         119.49,   -0.59,  103.04,   40.74,   97.59,   28.62,  -82.14,    2.68,  -37.39,  -93.23,  -34.24,   -4.76,   15.59,\n",
       "          11.83,   -7.10,  -74.59,   13.74,   -1.70,   14.05,   79.34,   85.69,   19.94,   19.70,  105.85,   57.62,    4.06,\n",
       "          22.64,  143.91,  116.68, -113.00,    4.70,  -52.45,  115.07,   36.34,  101.75,    3.77,   -2.66])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0 = model.layers[0]\n",
    "l0.b.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
