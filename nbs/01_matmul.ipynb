{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6654b91f-95cd-40cb-9d71-6ef6f55c111b",
   "metadata": {},
   "source": [
    "# Matrix multiplication from foundations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3ab27-ee7f-46b5-bbf6-7938f9bd1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle, gzip, math, os, time, shutil\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f647c-ce1d-4dc8-af88-70f9cf12f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bfbc0-7cd0-4673-93a4-4916e17a5227",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1e835-89ee-4cb4-b648-c3b71e87f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL = 'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=True'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723afd87-116e-42a4-824f-bf9b66a08d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm -rf {path_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135024d7-30ab-4130-a042-56cb2779535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8db69-8b64-416a-bcca-2eef0597e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c587350-2c4f-4dfe-a5e1-61f4410e129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16653\n",
      "-rw-r--r-- 1 root root 17051982 May 22 19:48 mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caff3a6-bea5-48bb-91fc-cf5eed9069d5",
   "metadata": {},
   "source": [
    "In terminal gz files can be extracted by using `gunzip mnist.pkl.gz`. We can check the encoding of the file using command line `file -i filename`. This will show us that the `pkl` file charset is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6016a5d-db0a-4380-b401-b13b658c9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d36b8-9a72-43c7-9b7b-3d17cafe431e",
   "metadata": {},
   "source": [
    "Take the first image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9cd16-d725-493d-9883-fcd54728a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.19140625,\n",
       " 0.9296875,\n",
       " 0.98828125,\n",
       " 0.98828125,\n",
       " 0.98828125,\n",
       " 0.98828125,\n",
       " 0.98828125]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = list(x_train[0])\n",
    "vals = lst1[200:210]\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0ee4b-2c75-4d52-973d-f025b27bf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(x, sz):\n",
    "    for i in range(0, len(x), sz): yield x[i:i+sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd66b9c-a445-43ed-9cba-7c126e613638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0],\n",
       " [0.19140625, 0.9296875, 0.98828125],\n",
       " [0.98828125, 0.98828125, 0.98828125],\n",
       " [0.98828125]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(chunks(vals, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017de600-d428-400e-9ccd-8f7f96430234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['image.cmap']='gray'\n",
    "plt.imshow(list(chunks(lst1,28)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85a261-a52b-41ea-a3d1-68763ca5a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d50a7-aebc-4235-9888-4c2d94738f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f1faa-654d-45e7-873b-8ad389fb1d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.19140625, 0.9296875]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(it, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41511c0-7156-4bb5-b17c-dfd4cc040955",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(lst1)\n",
    "img = list(iter(lambda: list(islice(it, 28)), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ab4bb-3354-4d6a-904e-af244af276bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92beddaf-2195-47d7-b504-1eb917ad2eed",
   "metadata": {},
   "source": [
    "Example with iter and islice, which takes an iterator an yields `stop` values starting from (skipping to) `start`, skipping each `step` indices between calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b55edb-2419-4ae5-b0a5-4f304efd23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "islice(iterable, stop) --> islice object\n",
       "islice(iterable, start, stop[, step]) --> islice object\n",
       "\n",
       "Return an iterator whose next() method returns selected values from an\n",
       "iterable.  If start is specified, will skip all preceding elements;\n",
       "otherwise, start defaults to zero.  Step defaults to one.  If\n",
       "specified as another value, step determines how many values are\n",
       "skipped between successive calls.  Works like a slice() on a list\n",
       "but returns an iterator.\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578aad7-adb9-45c7-bae9-1a83d18bf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = [i for i in range(100)]\n",
    "tst_iter = iter(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1798f2-a522-452c-856a-e3aa55d35cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9]\n",
      "[10, 11, 12, 13, 14]\n",
      "[15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(list(islice(tst_iter,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af542874-b1b0-46fc-8ef0-a86ef59c70fa",
   "metadata": {},
   "source": [
    "## Matrix and tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ceb2ec-e7de-4a43-bbc7-77f223bdb024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98828125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[20][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1c878-5468-4da3-a7fb-ee0fcfe07a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix():\n",
    "    def __init__(self, xs): self.xs = xs\n",
    "    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c5c84-e4d4-4ea0-ab91-cc0fafdd6552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98828125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Matrix(img)\n",
    "m[20,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24c0fa-755a-4cb0-9e07-f13b974eed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f1eed-f3dd-475a-ad81-a1a0fcdc0a63",
   "metadata": {},
   "source": [
    "To convert all of the lists to tensors, we can use `map` that takes function and applies it to iterables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f73354-e78b-4df8-aa8a-984056804852",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor,(x_train, y_train, x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57802a62-a240-4ccd-956d-dde4d4b3be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc62db-7202-40b2-a17b-d3ca65987a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN8klEQVR4nO3df6jVdZ7H8ddrbfojxzI39iZOrWOEUdE6i9nSyjYRTj8o7FYMIzQ0JDl/JDSwyIb7xxSLIVu6rBSDDtXYMus0UJHFMNVm5S6BdDMrs21qoxjlphtmmv1a9b1/3K9xp+75nOs53/PD+34+4HDO+b7P93zffPHl99f53o8jQgAmvj/rdQMAuoOwA0kQdiAJwg4kQdiBJE7o5sJsc+of6LCI8FjT29qy277C9lu237F9ezvfBaCz3Op1dtuTJP1B0gJJOyW9JGlRROwozMOWHeiwTmzZ50l6JyLejYgvJf1G0sI2vg9AB7UT9hmS/jjq/c5q2p+wvcT2kO2hNpYFoE0dP0EXEeskrZPYjQd6qZ0t+y5JZ4x6/51qGoA+1E7YX5J0tu3v2j5R0o8kbaynLQB1a3k3PiIO2V4q6SlJkyQ9EBFv1NYZgFq1fOmtpYVxzA50XEd+VAPg+EHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEi0P2Yzjw6RJk4r1U045paPLX7p0acPaSSedVJx39uzZxfqtt95arN9zzz0Na4sWLSrO+/nnnxfrK1euLNbvvPPOYr0X2gq77fckHZB0WNKhiJhbR1MA6lfHlv3SiPiwhu8B0EEcswNJtBv2kPS07ZdtLxnrA7aX2B6yPdTmsgC0od3d+PkRscv2X0h6xvZ/R8Tm0R+IiHWS1kmS7WhzeQBa1NaWPSJ2Vc97JD0maV4dTQGoX8thtz3Z9pSjryX9QNL2uhoDUK92duMHJD1m++j3/HtE/L6WriaYM888s1g/8cQTi/WLL764WJ8/f37D2tSpU4vzXn/99cV6L+3cubNYX7NmTbE+ODjYsHbgwIHivK+++mqx/sILLxTr/ajlsEfEu5L+qsZeAHQQl96AJAg7kARhB5Ig7EAShB1IwhHd+1HbRP0F3Zw5c4r1TZs2Feudvs20Xx05cqRYv/nmm4v1Tz75pOVlDw8PF+sfffRRsf7WW2+1vOxOiwiPNZ0tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX2GkybNq1Y37JlS7E+a9asOtupVbPe9+3bV6xfeumlDWtffvllcd6svz9oF9fZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJhmyuwd69e4v1ZcuWFetXX311sf7KK68U683+pHLJtm3bivUFCxYU6wcPHizWzzvvvIa12267rTgv6sWWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72PnDyyScX682GF167dm3D2uLFi4vz3njjjcX6hg0binX0n5bvZ7f9gO09trePmjbN9jO2366eT62zWQD1G89u/K8kXfG1abdLejYizpb0bPUeQB9rGvaI2Czp678HXShpffV6vaRr620LQN1a/W38QEQcHSzrA0kDjT5oe4mkJS0uB0BN2r4RJiKidOItItZJWidxgg7opVYvve22PV2Squc99bUEoBNaDftGSTdVr2+S9Hg97QDolKa78bY3SPq+pNNs75T0c0krJf3W9mJJ70v6YSebnOj279/f1vwff/xxy/PecsstxfrDDz9crDcbYx39o2nYI2JRg9JlNfcCoIP4uSyQBGEHkiDsQBKEHUiCsANJcIvrBDB58uSGtSeeeKI47yWXXFKsX3nllcX6008/Xayj+xiyGUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BHfWWWcV61u3bi3W9+3bV6w/99xzxfrQ0FDD2n333Vect5v/NicSrrMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcZ09ucHCwWH/wwQeL9SlTprS87OXLlxfrDz30ULE+PDxcrGfFdXYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSILr7Cg6//zzi/XVq1cX65dd1vpgv2vXri3WV6xYUazv2rWr5WUfz1q+zm77Adt7bG8fNe0O27tsb6seV9XZLID6jWc3/leSrhhj+r9ExJzq8bt62wJQt6Zhj4jNkvZ2oRcAHdTOCbqltl+rdvNPbfQh20tsD9lu/MfIAHRcq2H/haSzJM2RNCxpVaMPRsS6iJgbEXNbXBaAGrQU9ojYHRGHI+KIpF9KmldvWwDq1lLYbU8f9XZQ0vZGnwXQH5peZ7e9QdL3JZ0mabekn1fv50gKSe9J+mlENL25mOvsE8/UqVOL9WuuuaZhrdm98vaYl4u/smnTpmJ9wYIFxfpE1eg6+wnjmHHRGJPvb7sjAF3Fz2WBJAg7kARhB5Ig7EAShB1Igltc0TNffPFFsX7CCeWLRYcOHSrWL7/88oa1559/vjjv8Yw/JQ0kR9iBJAg7kARhB5Ig7EAShB1IgrADSTS96w25XXDBBcX6DTfcUKxfeOGFDWvNrqM3s2PHjmJ98+bNbX3/RMOWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dr7BDd79uxifenSpcX6ddddV6yffvrpx9zTeB0+fLhYHx4u//XyI0eO1NnOcY8tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXX240Cza9mLFo010O6IZtfRZ86c2UpLtRgaGirWV6xYUaxv3LixznYmvKZbdttn2H7O9g7bb9i+rZo+zfYztt+unk/tfLsAWjWe3fhDkv4+Is6V9DeSbrV9rqTbJT0bEWdLerZ6D6BPNQ17RAxHxNbq9QFJb0qaIWmhpPXVx9ZLurZDPQKowTEds9ueKel7krZIGoiIoz9O/kDSQIN5lkha0kaPAGow7rPxtr8t6RFJP4uI/aNrMTI65JiDNkbEuoiYGxFz2+oUQFvGFXbb39JI0H8dEY9Wk3fbnl7Vp0va05kWAdSh6W68bUu6X9KbEbF6VGmjpJskrayeH+9IhxPAwMCYRzhfOffcc4v1e++9t1g/55xzjrmnumzZsqVYv/vuuxvWHn+8/E+GW1TrNZ5j9r+V9GNJr9veVk1brpGQ/9b2YknvS/phRzoEUIumYY+I/5I05uDuki6rtx0AncLPZYEkCDuQBGEHkiDsQBKEHUiCW1zHadq0aQ1ra9euLc47Z86cYn3WrFmttFSLF198sVhftWpVsf7UU08V65999tkx94TOYMsOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkuc5+0UUXFevLli0r1ufNm9ewNmPGjJZ6qsunn37asLZmzZrivHfddVexfvDgwZZ6Qv9hyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaS5zj44ONhWvR07duwo1p988sli/dChQ8V66Z7zffv2FedFHmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T5A/YZkh6SNCApJK2LiH+1fYekWyT9b/XR5RHxuybfVV4YgLZFxJijLo8n7NMlTY+IrbanSHpZ0rUaGY/9k4i4Z7xNEHag8xqFfTzjsw9LGq5eH7D9pqTe/mkWAMfsmI7Zbc+U9D1JW6pJS22/ZvsB26c2mGeJ7SHbQ+21CqAdTXfjv/qg/W1JL0haERGP2h6Q9KFGjuP/SSO7+jc3+Q5244EOa/mYXZJsf0vSk5KeiojVY9RnSnoyIs5v8j2EHeiwRmFvuhtv25Lul/Tm6KBXJ+6OGpS0vd0mAXTOeM7Gz5f0n5Jel3Skmrxc0iJJczSyG/+epJ9WJ/NK38WWHeiwtnbj60LYgc5reTcewMRA2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLbQzZ/KOn9Ue9Pq6b1o37trV/7kuitVXX29peNCl29n/0bC7eHImJuzxoo6Nfe+rUvid5a1a3e2I0HkiDsQBK9Dvu6Hi+/pF9769e+JHprVVd66+kxO4Du6fWWHUCXEHYgiZ6E3fYVtt+y/Y7t23vRQyO237P9uu1tvR6frhpDb4/t7aOmTbP9jO23q+cxx9jrUW932N5Vrbtttq/qUW9n2H7O9g7bb9i+rZre03VX6Ksr663rx+y2J0n6g6QFknZKeknSoojY0dVGGrD9nqS5EdHzH2DY/jtJn0h66OjQWrb/WdLeiFhZ/Ud5akT8Q5/0doeOcRjvDvXWaJjxn6iH667O4c9b0Yst+zxJ70TEuxHxpaTfSFrYgz76XkRslrT3a5MXSlpfvV6vkX8sXdegt74QEcMRsbV6fUDS0WHGe7ruCn11RS/CPkPSH0e936n+Gu89JD1t+2XbS3rdzBgGRg2z9YGkgV42M4amw3h309eGGe+bddfK8Oft4gTdN82PiL+WdKWkW6vd1b4UI8dg/XTt9BeSztLIGIDDklb1splqmPFHJP0sIvaPrvVy3Y3RV1fWWy/CvkvSGaPef6ea1hciYlf1vEfSYxo57Ognu4+OoFs97+lxP1+JiN0RcTgijkj6pXq47qphxh+R9OuIeLSa3PN1N1Zf3VpvvQj7S5LOtv1d2ydK+pGkjT3o4xtsT65OnMj2ZEk/UP8NRb1R0k3V65skPd7DXv5Evwzj3WiYcfV43fV8+POI6PpD0lUaOSP/P5L+sRc9NOhrlqRXq8cbve5N0gaN7Nb9n0bObSyW9OeSnpX0tqT/kDStj3r7N40M7f2aRoI1vUe9zdfILvprkrZVj6t6ve4KfXVlvfFzWSAJTtABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL/DyJ7caZa7LphAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = x_train.reshape(-1, 28, 28)\n",
    "plt.imshow(imgs[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c7a43-6e7c-475f-b552-1f096b27bf8a",
   "metadata": {},
   "source": [
    "## Matrix multiplicaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d0899-ecd8-4acd-8cca-6b966a86dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "weights = torch.randn(784, 10) # 10 outputs\n",
    "bias = torch.zeros(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab33279-498d-4c72-afba-eeab744b57cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = x_valid[:5] # take a minibatch\n",
    "m2 = weights\n",
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2625ac-3953-49f2-a2af-5b331ea8bbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 784), (784, 10))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar, ac = m1.shape # n_rows * n_cols\n",
    "br, bc = m2.shape\n",
    "(ar,ac),(br,bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26ca02-038e-43da-9be5-ef6867fe87f8",
   "metadata": {},
   "source": [
    "Create variable to store intermediary result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632fb526-65cb-49f5-a069-1dd5fb50150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.zeros(ar, bc)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a1932-b9a8-40a7-be84-f1be8976e3b1",
   "metadata": {},
   "source": [
    "Consider first matrix multiplication with three loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d748c88-c020-4880-b17d-263010cb9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ar): # 5 rows\n",
    "    for j in range(bc): # 10 columns\n",
    "        for k in range(ac): # 784 entries\n",
    "            t1[i,j] += m1[i,k] * m2[k,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e305014-adca-4aa4-a82e-f016487983f3",
   "metadata": {},
   "source": [
    "A very useful comand is to set torch printing options in order to use more than 80 cols. It is useful to include it by default on top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52a4d1-f010-4e09-883f-1f47afee9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d7aae-643c-4f65-880f-1ce8037754ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1641c-e71d-4d48-a44b-8c9d2fbb7bf3",
   "metadata": {},
   "source": [
    "Now let's convert cells above to a function. A useful trick it to copy those cell (press `C` and `V` in M mode) and then select all the cells and press `Control + M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246cc39-7e34-4230-bcd7-5db5290ba965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    \n",
    "    # set rows and cols\n",
    "    (ar,ac), (br,bc) = m1.shape, m2. shape\n",
    "    \n",
    "    # prepare output\n",
    "    t = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar): # 5 rows\n",
    "        for j in range(bc): # 10 columns\n",
    "            for k in range(ac): # 784 entries\n",
    "                t[i,j] += m1[i,k] * m2[k,j]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89769ad-ca04-4b77-86b2-2a78bdf8cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb48d5-d858-461d-8133-20a8e4268a9d",
   "metadata": {},
   "source": [
    "We can check, how long does it take to run a function by using magic function `%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fbb3e-422a-4ef1-91c6-8b12d790e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 ms ± 30.2 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783603f-822b-4fe4-a0cd-798ef5809217",
   "metadata": {},
   "source": [
    "So this takes almost half a second to run, which is way too much and will not allow us to use matmul for large datasets (here we are using just a batch of 5 images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e2845-e970-410e-ae26-6ed427b47f25",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb650645-8119-4781-b596-61fbf02db83f",
   "metadata": {},
   "source": [
    "One possible way to speed things up it to use numba. We will use it to speed up the most inner loop (which is the largest one as it is 784 items long). Numba works with numpy, so we import numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d9e16-c81a-41dd-bb63-97ed5d552917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38af0b-3872-4ea3-b654-da2462558968",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def dot(a, b):\n",
    "    res = 0.0\n",
    "    for i in range(len(a)): res += a[i] * b[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb6ac3-600a-45d3-8c0a-ae0d9d84ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    \n",
    "    # set rows and cols\n",
    "    (ar,ac), (br,bc) = m1.shape, m2. shape\n",
    "    \n",
    "    # prepare output\n",
    "    t = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar): # 5 rows\n",
    "        for j in range(bc): # 10 columns\n",
    "            t[i,j] = dot(m1[i, :], m2[:,j]) # 784 entries\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079377b3-51fb-486d-ac43-29a25dddeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1a, m2a = m1.numpy(), m2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b3b21-f213-4453-ab40-9343ebc00ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(m1a, m2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16ecd7-c912-4f5f-9876-43957750e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae7258-3e98-4923-937f-4a1fc995ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1a, m2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f3c3e-eef8-4e61-8ec2-18693735e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 µs ± 6.56 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1a, m2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7beb5-2db2-4886-9f5c-90c313c9c9a3",
   "metadata": {},
   "source": [
    "We managed to speed up one loop and our results is more than 550 times times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89104f-5e57-4eab-b169-2b0753748846",
   "metadata": {},
   "source": [
    "## Elementwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2378f2-6316-4b5a-b2fc-d801d8a8b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419c6b8-9af2-4f46-96ed-906e08eec3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a < b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2379d-2115-485e-b6ae-a54ff5611213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.67)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf9fd8-ec8e-4ff6-ad19-d9cad6c9c092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff95ba-ea5f-43e1-876c-a4b3037e86ad",
   "metadata": {},
   "source": [
    "Frobenius norm: $\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967b020-8b14-4527-9913-d0c11c705308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.88)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frob_n = (m*m).sum().sqrt()\n",
    "frob_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eee2f4-dac0-4c0c-8214-8befab4219cd",
   "metadata": {},
   "source": [
    "Now we rewrite our matrix multiplication function using broadcasting to get rid of one loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb72e5f-1693-444c-9933-db54e8ca25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    \n",
    "    # set rows and cols\n",
    "    (ar,ac), (br,bc) = m1.shape, m2. shape\n",
    "    \n",
    "    # prepare output\n",
    "    t = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar): # 5 rows\n",
    "        for j in range(bc): # 10 columns\n",
    "            t[i,j] = (m1[i, :] * m2[:,j]).sum() # 784 entries\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb02746-e684-4a5d-904b-066f8f43f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4761bbf-f433-45a9-98db-6b7b27a83f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 µs ± 27.2 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841ac98-899d-42c3-9baa-58039cf82725",
   "metadata": {},
   "source": [
    "Slower than Numba implementation but still much faster than the initial version. Basically we have recreated above the `torch.dot`. We can use it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b315255-28f8-430c-878a-23b6f4172436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    \n",
    "    # set rows and cols\n",
    "    (ar,ac), (br,bc) = m1.shape, m2. shape\n",
    "    \n",
    "    # prepare output\n",
    "    t = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar): # 5 rows\n",
    "        for j in range(bc): # 10 columns\n",
    "            t[i,j] = torch.dot(m1[i,:], m2[:,j]) # 784 entries\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8aafe-28e2-4ae4-945b-542deb755bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebe5ba-08da-4898-b841-17fe5d6c9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535 µs ± 16.5 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6170a-4ba3-47d9-80da-aecc46052b55",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e6679-a527-4972-8712-663dbffd3b81",
   "metadata": {},
   "source": [
    "Broadcasting is crucial to deep learning techniques and efficient code writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c94f33-7798-4a41-a8aa-38eff2be33fa",
   "metadata": {},
   "source": [
    "### Broadcasting to a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dc740-fda2-4926-a105-2303799eca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  6., -4.])\n",
      "tensor([ True,  True, False])\n"
     ]
    }
   ],
   "source": [
    "print(a); print(a>0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b15c07-fd9d-4ef7-b2e8-9bce7d276c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.],\n",
      "        [14., 16., 18.]])\n"
     ]
    }
   ],
   "source": [
    "print(m), print(m*2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e8915-3f7d-4372-b0ce-dd91f10b3703",
   "metadata": {},
   "source": [
    "### Broadcasting a vector to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de2b5b-172e-417c-ad05-e6087a7e5f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f738c-da49-4e23-bd6e-cfa868290c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ceadb-e910-4afb-98e7-cfae78872d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111940a7-3d6f-4425-ac9d-5e11ee675124",
   "metadata": {},
   "source": [
    "`c` is broadcastable to `m`. We can check how `c` will be represented during the broadcast using `expand_as` method. Note that rows / columns are not actually copied.\n",
    "\n",
    "By calling `storage` method we can check how expanded array is stored internally. To achieve this, t uses a stride of (0,1) which means that its rows are all pointing to the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b2afc-6f6a-41e9-826e-36d7cac726af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = c.expand_as(m); t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828aa95-63a0-41cc-adb5-68bc2f9f8fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77d0ef-cbae-4337-a3cb-842df239840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f3992-9d8e-4692-8e1a-462eded9756c",
   "metadata": {},
   "source": [
    "We can index with the special value `None` or use `unsqueeze()`` to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20613c47-febc-499b-932d-87e4ba020419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]),\n",
       " tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(1), c[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249074a3-b11c-457d-9ea2-ded80c40ba4b",
   "metadata": {},
   "source": [
    "Indexing with `None` or calling `unsqueeze()` is important in order not to mess up with the shapes and broadcasting. Consider the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c9f3b5-feee-4120-b03a-84f4d91a8a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9871e-89c7-474e-a539-803e032af90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0077ea-daae-47cd-9c4a-bca92704cc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [24., 25., 26.],\n",
       "        [37., 38., 39.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86667de1-728e-40c6-8a45-2fddb43b76f6",
   "metadata": {},
   "source": [
    "### Broadcasting rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9bed4-d2c2-47fd-a80a-cab67771906e",
   "metadata": {},
   "source": [
    "Two tensors are broadcastible if their shapes are compatible. The comparison of shapes is performed elementwise starting from the trailing (right) dimension. Two dimensions are **compatible** if:\n",
    "1. those dimensions are the same or\n",
    "2. one of them is 1 in which case it will be broadcasted to the same size\n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a 256\\*256\\*3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible. That's why we get different results when indexing with `None` into [c] tensor: \n",
    "\n",
    "\n",
    "    Image  (3d array): 256 x 256 x 3\n",
    "    Scale  (1d array):             3\n",
    "    Result (3d array): 256 x 256 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228edf8-6b12-4514-92e1-cda933b55116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.shape = [3] -> [1, 3] -> [3, 3]\n",
    "m + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad2fe1-b8c3-4bce-9be3-b6bc0e865f01",
   "metadata": {},
   "source": [
    "### Matmul with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758b798-ac80-4e49-a362-87739ad11b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit = m1[0]\n",
    "digit.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856dbc1-c9d0-4ae1-b40d-2955b2997a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0.,  ..., -0., -0., 0.],\n",
       "        [-0., -0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., -0.],\n",
       "        ...,\n",
       "        [0., 0., -0.,  ..., 0., 0., -0.],\n",
       "        [0., 0., 0.,  ..., -0., 0., -0.],\n",
       "        [-0., 0., -0.,  ..., -0., -0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit[:, None] * m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94e5d1-4b3a-4410-807e-b8a17cc96754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d0fab-0281-43eb-9661-d650487eeee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2):\n",
    "    \n",
    "    # set rows and cols\n",
    "    (ar,ac), (br,bc) = m1.shape, m2. shape\n",
    "    \n",
    "    # prepare output\n",
    "    t = torch.zeros(ar, bc)\n",
    "\n",
    "    for i in range(ar): # 5 rows\n",
    "        # (784,1) is broadcasted to (784, 10) and multiplied by (784,10)\n",
    "        t[i] = (m1[i,:, None] * m2).sum(axis=0)\n",
    "        # t[i,j] = torch.dot(m1[i,:], m2[:,j]) # 784 entries\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5bb9b-0d8b-46c3-9471-41b4c5def71a",
   "metadata": {},
   "source": [
    "It is very important to undersand the function above. Inside the loop we go through each row of matrix $m1$ which is of length 784. Instead of multiplied this row in a loop by each column of the matrix $m2$ (which is of length 784) we do it all at once by broadcasting the row of $m1$ to (784, 10) and multiplying by $m2$: \n",
    "\n",
    "    m1             -> (5, 784)\n",
    "    m1[0]          -> (784)\n",
    "    m1[0, :, None] -> (784, 1)\n",
    "    broadcasted to -> (784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739819a-0175-4303-88c6-9be2faa4921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0,:,None].shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684cd47-36c8-444c-91d3-65a5572aa973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -0.,  ..., -0., -0., 0.],\n",
       "        [-0., -0., -0.,  ..., -0., 0., 0.],\n",
       "        [0., 0., -0.,  ..., -0., 0., -0.],\n",
       "        ...,\n",
       "        [0., 0., -0.,  ..., 0., 0., -0.],\n",
       "        [0., 0., 0.,  ..., -0., 0., -0.],\n",
       "        [-0., 0., -0.,  ..., -0., -0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0,:,None] * m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6b025-6d56-40dc-ab3b-bbf841d418af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99f598-ccda-4e75-8b1b-e5ec4203de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 µs ± 40.7 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d5b17-4c0a-45e0-8986-8118bb6ee775",
   "metadata": {},
   "source": [
    "So we have gone from 500 ms to less than 0.1 miliseconds, which is faster by a factor of 5000!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616034e-bfc2-4baa-810c-818509640eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.96,  -2.96,  -2.11,  ..., -15.09, -17.69,   0.60],\n",
       "        [  6.89,  -0.34,   0.79,  ..., -17.13, -25.36,  16.23],\n",
       "        [-10.18,   7.38,   4.13,  ...,  -6.73,  -6.79,  -1.58],\n",
       "        ...,\n",
       "        [  7.40,   7.64,  -3.50,  ...,  -1.02, -16.22,   2.07],\n",
       "        [  3.25,   9.52,  -9.37,  ...,   2.98, -19.58,  -1.96],\n",
       "        [ 15.70,   4.12,  -5.62,  ...,   8.08, -12.21,   0.42]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = matmul(x_train, weights)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d7ded-04df-4fe0-a3c4-4451c971e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 0 ns, total: 791 ms\n",
      "Wall time: 757 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282191e1-c34c-4515-a727-919e21fba2f3",
   "metadata": {},
   "source": [
    "##  Einstein summation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c93df-79a8-49b3-a1e2-64ae2b1ac5f9",
   "metadata": {},
   "source": [
    "Einstein summation is a compact representation for combining products and sums in a general way. The key rules are:\n",
    "* Repeating letters between input arrays means that values along those axes will be multiplied together.\n",
    "* Omitting a letter from the output means that values along that axis will be summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc9fb6-7ae1-4005-b905-6c4ae4f2fc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b89813-a740-4937-8729-34c9bfcdc545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 784, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c[i,j] += a[i,k] * b[k,j]\n",
    "# c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "mr = torch.einsum('ik,kj->ikj', m1, m2)\n",
    "mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85a7dd-d730-4bb0-81f0-2d9a4832a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5f278-ca0e-4fa2-ba9d-25109c3684c7",
   "metadata": {},
   "source": [
    "By summing over the 1st dimension we get back our resulting matrix. If the omit the $k$, the values over that axis will be summed automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f08549-cc47-445f-beb2-6bad2fe2da8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = torch.einsum('ik,kj->ij', m1, m2)\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc4921-f065-40e7-8ed9-ebde59f70594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(m1, m2): return torch.einsum('ik,kj->ij', m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ac98d-3672-4427-ab18-76cab10ac432",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c40fa-6a16-463b-aa8e-51057a2c7829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 µs ± 5.53 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b6754-a463-4ef3-9fee-e6f33594ae0e",
   "metadata": {},
   "source": [
    "## pytorch op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140469a-d5b1-4926-b374-9da1f65c4980",
   "metadata": {},
   "source": [
    "We can use pytorch built-in operator for matrix multiplication: `@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8aa4e-b2f8-4ffe-bd82-ec6aaf1f9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(t1, m1@m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5ab96-4ccd-421b-8b98-fb578f36ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.38 µs ± 3.49 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 m1@m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab320e7-1c92-4663-b32a-2942deb8ad7a",
   "metadata": {},
   "source": [
    "##  CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab7523-a26d-40cf-864f-6eb987941d09",
   "metadata": {},
   "source": [
    "GPUs are greate at running things in parallel. We rewrite our matrix multiplication f-n to calculate the result for each separete cell (grid). As each calculation is indepent of other we can call them all in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fbba6-d70c-41ce-af17-ce242d25487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(grid, # coordinates\n",
    "           a, # matrix 1\n",
    "           b, # matrix 2\n",
    "           c): # resulting matrix (a @ b)\n",
    "    i, j = grid\n",
    "    assert (i < a.shape[0]) & (j < b.shape[1]), \"Wrong shapes, mate\"\n",
    "    temp = .0\n",
    "    for k in range(a.shape[1]): temp += a[i, k] * b[k, j]\n",
    "    c[i,j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71988f89-ddc5-486c-adb4-e8b9bb045048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n",
       "        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n",
       "        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n",
       "        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n",
       "        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "matmul((0,0), m1, m2, res)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab856a40-3a49-4f2b-960d-eb7f4dd031d7",
   "metadata": {},
   "source": [
    "Launch kernel takes a kerenel (a function) and calls it on a grid. We can check that the result is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a12d4-6bd4-4b85-9a0d-5116e586ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n",
    "    for r in range(grid_x):\n",
    "        for c in range(grid_y): kernel((r,c), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e74bcd-fcbd-4355-9b49-2f7282eebc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.zeros(ar, bc)\n",
    "launch_kernel(matmul, ar, bc, m1, m2, res)\n",
    "test_close(res, t1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db8b15-46a5-40f5-a1e3-74d649afa50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c9499-bf7b-4fa3-8af4-6b0e7daa9ce9",
   "metadata": {},
   "source": [
    "We need to make a small adjustment to our f-n to run on GPU. From CUDA Refresher: A group of threads is called a CUDA block. CUDA blocks are grouped into a grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112f3f7-6586-45ab-bbd0-78e48bd4c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(a, # matrix 1\n",
    "           b, # matrix 2\n",
    "           c): # resulting matrix (a @ b)\n",
    "    i, j = cuda.grid(2)\n",
    "    assert (i < a.shape[0]) & (j < b.shape[1]), \"Wrong shapes, mate\"\n",
    "    temp = .0\n",
    "    for k in range(a.shape[1]): temp += a[i, k] * b[k, j]\n",
    "    c[i,j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44923aaf-cb64-40f4-9b5e-c6dfc52023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.zeros_like(tr)\n",
    "m1g, m2g, rg = map(cuda.to_device, (x_train, weights, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861fe17-849c-4955-8442-5d0ff175654f",
   "metadata": {},
   "source": [
    "Boilerplate code below to split execution into blocks per grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3779744-08ce-45fd-bdd5-fa34f2a27ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPB = 16\n",
    "rr,rc = r.shape\n",
    "blockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n",
    "blockspergrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b49df3-db6e-4671-8ffb-39cd1763b6cd",
   "metadata": {},
   "source": [
    "To launch the kernel the signature is as follows: kernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n",
    "\n",
    "See https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6182c2f-e2b1-477a-9ee0-3e74a0ba6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul[blockspergrid, (TPB, TPB)](m1g, m2g, rg)\n",
    "r = rg.copy_to_host()\n",
    "test_close(tr,r, eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f147d6-3634-4a36-b447-be95d381cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5 ms ± 1.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
    "r = rg.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ef8cc-a230-4a1c-becf-8e01c4a853a5",
   "metadata": {},
   "source": [
    "We can go even faster without using our own implementation but relying on pytorch op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac44778-3e87-4fe0-963a-2b86ea7b1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c, m2c = x_train.cuda(), weights.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7574a2-d381-4952-ad3b-9c22576a3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (m1c @ m2c).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a46a55-71b3-4019-929c-d8fcc28b9faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62 ms ± 602 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 res = (m1c@m2c).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756cc262-8824-4499-8b2d-7ecfdfec5895",
   "metadata": {},
   "source": [
    "Our broadcasting version was >500ms, and our CUDA version is around 1ms, which is 500x improvement compared to broadcasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
