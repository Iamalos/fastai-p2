{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6847b7-6494-4cea-9f44-08bdb23d55b2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e17534-8fb2-4589-870a-dd7904b4fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245f39b-2337-4d49-aeb6-43673e2ce05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,shutil,torch,matplotlib as mpl, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor, nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a37cf-f6e1-42e9-81d6-e8e5400ed86d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mnist.pkl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m path_gz \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist.pkl.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(path_gz, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: (x_train, y_train), (x_valid, y_valid), _ \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m x_train,y_train,x_valid,y_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(torch\u001b[38;5;241m.\u001b[39mtensor,[x_train,y_train,x_valid,y_valid])\n",
      "File \u001b[0;32m/usr/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m/usr/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/mnist.pkl.gz'"
     ]
    }
   ],
   "source": [
    "from fastcore.test import test_close\n",
    "torch.set_printoptions(precision=2, linewidth=180, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path = Path('data')\n",
    "path_gz = path / 'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: (x_train, y_train), (x_valid, y_valid), _ = pickle.load(f, encoding='latin-1')\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = map(torch.tensor,[x_train,y_train,x_valid,y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353abb34-cf19-4321-acee-49f6008363f1",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1d078-c93c-428e-87bb-6770c001ae44",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb253d2-8b60-4461-bf2c-0de10f9ebbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef004684-b78e-46e7-9ace-c241e3330620",
   "metadata": {},
   "source": [
    "Here is the simple nn implementation from the previous notebook. We will start building from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc87c5-9400-4b80-82eb-dbe83a017ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a207e-7155-47a5-a012-0d45bb919d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28470b34-67f9-4e84-8239-06aa4afcd204",
   "metadata": {},
   "source": [
    "## Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d87f85-c685-46e8-9d5a-748095212f24",
   "metadata": {},
   "source": [
    "x here is a matrix of logits (outputs of the last layer of a nn). We convert logits to probabilities using softmax defined below.\n",
    "\n",
    "$$ \\hbox{softmax(x)}_{i} = \\frac{e^{x}}{e^{x_{0}} +e^{x_{1}} + \\cdots + e^{x_{n-1}} } $$\n",
    "\n",
    "$$ \\hbox{softmax(x)}_{i} = \\frac{e^{x}}{\\sum\\limits_{0 \\leq j \\leq n}{e^{x_{j}}}} $$\n",
    "\n",
    "Cross-entropy takes log of probabilities so we will define log_softmax function. # when working with a matix of (n,m) we can use `sum(1, keepdims=True)`. If we have extra dimension (batches) then we will nedd to sum across 2-nd dimension. To captue all of those cases we can just sum across the last dimension (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77444a6f-4317-42fa-b083-3c668708b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1, keepdims=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f152bb-3131-46b7-92d6-d0a52876e324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad7e9d-3a92-4fdc-b185-c1a8987ff249",
   "metadata": {},
   "source": [
    "When working with logs, we can take advantage of the following relation:\n",
    "\n",
    "$$ \\log(\\frac{a}{b}) = \\log(a) - \\log(b) $$\n",
    "\n",
    "This will also add more stability and help avoid problems related to division (division by zero, exploding numbers, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ca9b5-354e-479a-ae7a-1977e6a75454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - (x.exp().sum(-1, keepdims=True)).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ded23-b5ff-4db4-9034-ca4fe0fb4684",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
    "\n",
    "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
    "\n",
    "This allows to avoid getting very large numbers during exponentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997651a-fdf0-4135-b16c-ef671de5f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(dim=-1)[0]\n",
    "    return m + ((x-m[:, None]).exp().sum(-1)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edd04f-8088-44b9-9e62-6bb89411e4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsumexp(pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd55d1-38d4-490c-a385-d1f3a1faa513",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85b9b5-dfc1-464d-9a06-c8ee7dc5944f",
   "metadata": {},
   "source": [
    "We have recreated the built-in pytorch method `logsumexp` so we will use it going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f4eab-4a65-4b7e-aa85-ecffa69f99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03ece9-17ae-417a-9e93-5af7aa4b95d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0fbfb2-fb4e-4162-9e0f-02312d044362",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by: \n",
    "$$ -\\sum x \\log p(x) $$\n",
    "\n",
    "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target. This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing) which is supported by PyTorch as well.\n",
    "\n",
    "As a quick reminder, cross entrop loss simply finds the correct class and takes its log probability. If we have a perfect match the loss is zero $(log(1))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f6fed-3fa9-4613-8b7e-ce821a8ab547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c344681-9b40-4e02-a479-88a922f2ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36, -2.19, -2.32, -2.20, -2.32, -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44, -2.33, -2.30, -2.16, -2.34, -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28, -2.09, -2.36, -2.30, -2.38, -2.30, -2.30, -2.27]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae905c-26e3-4475-8473-9a348acf974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.20, -2.37, -2.36], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b148c-51be-41f6-8224-188f509a8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(input.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015009b7-1d17-4166-990b-4ec6b496356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666ffd1-de29-463d-b169-efd1fa7f1b55",
   "metadata": {},
   "source": [
    "Let's check our results against the PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228548b-3759-4dde-902e-fdb19ee12614",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(loss, F.nll_loss(sm_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3977b7e-110b-4944-9285-b691f010cd89",
   "metadata": {},
   "source": [
    "PyTorch combines all of the above steps (`F.log_softmax` and `F.nll_loss`) into a single optimized function - `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c61c7e-0c63-46c2-9f5c-42a3892bbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6135b-980e-447f-82b9-05acc1066dcd",
   "metadata": {},
   "source": [
    "# Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd942bf9-c2d6-4050-8f1d-eda42c88c335",
   "metadata": {},
   "source": [
    "The basic training loop:\n",
    "* get the output of the model on a batch of inputs\n",
    "* compare the output to the true labels and compute the loss\n",
    "* calculate the gradients of the loss with respect ot every parameter\n",
    "* update said parameters with those gradients to make loss a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e30ce-ff32-405a-a7d7-f77b2cf47deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674c0bc-bdf3-4a7d-8751-66700f1710b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50 # batch size\n",
    "xb = x_train[:bs]\n",
    "preds = model(xb)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce005d5-ada9-4578-ab23-632450c5b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432baa0c-1b98-4c0c-a571-dc028abda642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.84)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7440ee1-3d6a-4520-b54f-ca0e1d7d3a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 6, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmin(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe4a53-de5a-406f-9356-57cfd6012f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e67155-c858-40a7-80ce-b516cb3250dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0ad01-536f-48dd-971c-937908815c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.14)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds.argmin(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8a58c-b192-4c0b-a074-0307f8802930",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5 # learning rate\n",
    "epochs = 3 # epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76220c-ceed-4bba-8741-71d7ffddf0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def report(loss, preds, yb): print(f'{loss:.2f}, accuracy:{accuracy(preds,yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25731121-3285-4228-ad72-d8fc9e3678eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30, accuracy:0.08\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "pred = model(xb)\n",
    "loss_func(pred, yb)\n",
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbde291-9c15-4792-99e1-2c8ddbe89048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, accuracy:0.98\n",
      "0.12, accuracy:0.94\n",
      "0.08, accuracy:0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): # for each epoch\n",
    "    for i in range(0, n, bs): # getting index for each next batch\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight += -lr * l.weight.grad\n",
    "                    l.bias += -lr * l.bias.grad\n",
    "                    l.weight.grad = None\n",
    "                    l.bias.grad = None\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c327e3-d82f-4a2a-a98c-370879a30db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.02, -0.02, -0.01,  ...,  0.01, -0.00,  0.00],\n",
       "        [-0.03, -0.02, -0.03,  ..., -0.00,  0.00, -0.02],\n",
       "        [ 0.03, -0.01, -0.03,  ..., -0.01,  0.01, -0.03],\n",
       "        ...,\n",
       "        [-0.02, -0.01,  0.03,  ...,  0.02, -0.02,  0.02],\n",
       "        [ 0.02,  0.03, -0.03,  ..., -0.00,  0.03, -0.02],\n",
       "        [ 0.01,  0.00, -0.00,  ...,  0.03,  0.00,  0.03]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6419510-9984-4fc4-90f9-029f413cafff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.02, -0.02, -0.01,  ...,  0.01, -0.00,  0.00],\n",
       "        [-0.03, -0.02, -0.03,  ..., -0.00,  0.00, -0.02],\n",
       "        [ 0.03, -0.01, -0.03,  ..., -0.01,  0.01, -0.03],\n",
       "        ...,\n",
       "        [-0.02, -0.01,  0.03,  ...,  0.02, -0.02,  0.02],\n",
       "        [ 0.02,  0.03, -0.03,  ..., -0.00,  0.03, -0.02],\n",
       "        [ 0.01,  0.00, -0.00,  ...,  0.03,  0.00,  0.03]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c016d-b97f-4ea2-bc1d-5bf4e0be0913",
   "metadata": {},
   "source": [
    "# Using Parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d6732-ea07-4443-ad25-17cea6eb2b6a",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956e994-d8af-4fab-ac9a-2eeca03be8ad",
   "metadata": {},
   "source": [
    "This is not the intended usage of `nn.Module` but it can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585813d-e11c-4bc9-9983-ccd15d7c2165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48650b41-58d8-4291-aefc-9b133ad7ec72",
   "metadata": {},
   "source": [
    "We can check the children of `m1` and all of its `parameters`. The methods below return generators, so we wrap them intol lists to get back the stored values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbfa16-b0d9-4bd8-970e-d75ca23c45b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fa3c0-2a48-418a-8acb-f3aac9082b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c0ca2-d570-43af-b750-afc9bd70491c",
   "metadata": {},
   "source": [
    "We can recreate this functionailty ourselves. Note, that we don't need the special `__call__` method, because the implement the `forward` method that is called automatically by` __call__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe053b4-713d-4570-b3a6-c3bae44825c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x): return   self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35851f-3b3a-4bcb-b419-26142d115159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebf3b4-5258-4412-8919-69a0c0af98d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children(): print(f'{name}: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ddd71-c506-4c6f-9c58-26d532d939ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8694d-3ebf-4482-b9fc-0b51bd524459",
   "metadata": {},
   "source": [
    "We can use `parameters` to update the weights without calling each layer separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f758ec3-a032-44e6-a183-70747cf294a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(i+bs, n))\n",
    "            #import ipdb; ipdb.set_trace()\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): \n",
    "                    p += -lr * p.grad\n",
    "                    p.grad = None\n",
    "                \n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032a7d8-d037-4beb-80c6-7f496cd6affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, accuracy:0.96\n",
      "0.11, accuracy:0.96\n",
      "0.04, accuracy:1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2273b8-1acb-4d52-bf8a-6f794c639fff",
   "metadata": {},
   "source": [
    "PyTorch knows what parameters are by using `__setattr__`. The `__setattr__` method is called each time an attribute is set, just before the actual assignment occurs. This allows us automatically to include the relevant layers to the dict module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db04ae-022e-4ad1-a383-ce4296b6a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "\n",
    "    def parameters(self):\n",
    "        for l in self._modules.values(): yield from l.parameters()\n",
    "            #for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1d9ce-32b9-4b1f-b5bf-9cb09ecbe6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = MyModule(m, nh, 10)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c461d-f8a3-4ef1-93a8-6ae68e140861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in o.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117675df-aa25-452b-8e70-8c77956f10fd",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5bb4aa-b877-4b6a-999a-3643b7e2c9cc",
   "metadata": {},
   "source": [
    "This apporach will not work when we define layers all at once in the list:\n",
    "`self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]`. We need to register each of them as modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a01dc-44b7-49f6-b7fd-302bccd59b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d9f13-f2ce-4370-85be-bafa2d12e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090351f6-6792-40fe-bbba-0a5941aa26b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4e944-d7f8-4e4d-921c-cf7bc83705e5",
   "metadata": {},
   "source": [
    "`Reduce` applies a function of two arguments cumulatively to the items of a sequence,\n",
    "from left to right. If initial value is provided (x) it is placed before the items\n",
    "of the sequence. This is is equivalent to\n",
    "```\n",
    "for l in self.layers: x = l(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d25ae-5dea-4365-ae25-baac8ddfac73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation of factorial with reduce\n",
    "reduce(lambda x,y: x*y, range(1,11), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519d511-15a3-43c4-9a33-c1facbc22fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def forward(self, x): return reduce(lambda x, l: l(x), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffc696-d302-4c66-9ac3-46f0361068ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ec916-283a-44ad-9a82-12234a88096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922b616-7331-4280-80f3-a448b7b9ba98",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb323833-da0b-4e8d-9fb7-a7f01be7bfae",
   "metadata": {},
   "source": [
    "Instead of manually calling `add_module` on the layers, we can use PyTorch class `nn.ModuleList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87021667-540d-425e-9130-89e2cc83f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda x,l: l(x), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33bd97-42f0-485c-828e-4ef00a9e3fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f122ac-51ca-463e-ba55-d40ca961143b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, accuracy:0.96\n",
      "0.11, accuracy:0.96\n",
      "0.07, accuracy:0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329b01d-e591-457f-90ab-ba354489c3f8",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e68385-fb28-42b0-95ed-1b4486ab4cfd",
   "metadata": {},
   "source": [
    "`nn.Sequential` does the same as above in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bceb8-b15f-4e38-979d-95a77d25ac75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=784, out_features=50, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=50, out_features=10, bias=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9ddb5-f338-461f-a765-b8403349d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150681c7-d009-42a0-8ff9-204e4716a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05, accuracy:0.98\n",
      "0.03, accuracy:1.00\n",
      "0.02, accuracy:1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.01, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3314c-7440-40f1-b6b6-04be82a60ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f2826-725a-4703-bd0a-0988708bbe2e",
   "metadata": {},
   "source": [
    "### nn.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fbcc5-fc7e-41c8-89ce-3ac840d5fcf2",
   "metadata": {},
   "source": [
    "Now let's create our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a35e33-89c3-460c-822d-42318545e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= self.lr * p.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406573d-e192-4bc8-b8cb-c3f3135aea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544c5cd-fc78-49cb-80e5-b1d8478c35cb",
   "metadata": {},
   "source": [
    "Now we can rewrite our training loop as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e75158-fb77-4a34-82bc-7e187c9a13e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16, accuracy:0.94\n",
      "0.13, accuracy:0.96\n",
      "0.08, accuracy:0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165ceb1-89d2-4ffe-a043-90d55788c4bc",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b81b7-0fa1-402d-b1d5-421c5b0cd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f6cb4-80fd-47fe-8757-b83b14191778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52246b03-7bc2-44df-8ef5-446eb493cad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0dd42-e101-4ec6-8044-f716f2e5f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18, accuracy:0.94\n",
      "0.13, accuracy:0.96\n",
      "0.11, accuracy:0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70520be2-2fe0-4b91-bf0f-7b10b79eb25b",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79492f-260f-49d6-8cce-07fd4893a9fc",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7a359-0c38-45e2-922b-bc9853e4b5ba",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "```\n",
    "Instead, let's do these two steps together, by introducing a Dataset class:\n",
    "```python\n",
    "xb,yb = train_ds[s]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08657ca-2367-4692-af76-4b6784043c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "    def __init__(self, x, y): self.x, self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return (self.x[i], self.y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05c04d-f539-42e6-88bf-9a7a7f11b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3612d-fc38-4598-9996-5cc646356674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5,m)\n",
    "assert yb.shape == (5,)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877a402-1337-4cf5-8d31-f5516844dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120aea45-baaf-4fa0-bc04-8a4ceaf699ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, accuracy:0.98\n",
      "0.09, accuracy:0.98\n",
      "0.07, accuracy:0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb, yb = train_ds[i:min(i+bs, n)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceceae8f-01a8-41dd-b266-815a3aae5901",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd3f07-6f2a-45d7-ac58-bb4696bc144c",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "\n",
    "```python\n",
    "for i in range(0, n, bs):\n",
    "    xb,yb = train_ds[i:min(n,i+bs)]\n",
    "    ...\n",
    "```\n",
    "Let's make our loop much cleaner, using a data loader:\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Dataloader will allow us to iterate through the data without explicitly writing out the loop. This is aschieved by using `__iter__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca81422-66fd-4e31-b48c-14a30b6b592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        n = len(self.ds)\n",
    "        for i in range(0, n, self.bs): yield self.ds[i:min(i+self.bs, n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9fd01-cda4-44ee-a3ad-8a56d5b6e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, bs)\n",
    "valid_dl = Dataloader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418d7b7-065e-41ad-a958-dab8b2c25fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd880e-9fc5-4bd5-8924-6b71a9176aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28));\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7603a8-cdf3-4eb9-8b49-99ba7d9ec62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d2410-70c6-4245-bbed-47ebc55c720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17, accuracy:0.96\n",
      "0.11, accuracy:0.94\n",
      "0.09, accuracy:0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fafe82-cff3-4683-8f9a-740ffd73e47f",
   "metadata": {},
   "source": [
    "Great! We singificantly simplified the training loop. Now let's build on top of this an firstly tackle random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202849b-717a-48cf-8085-c8944b37103f",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e001ab-2b4e-479c-9ddd-86ab763f3a09",
   "metadata": {},
   "source": [
    "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103f7b4-2972-4e91-be9f-10d8b75ecfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bd628-45a8-4a76-a61a-636f7b7a8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ds, shuffle=False): self.ds, self.shuffle = ds, shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(len(self.ds)))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f813-7dfb-43d3-b119-ef1e37bce0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds, shuffle=False)\n",
    "it = iter(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407f157-4f50-4b19-be6f-5a7a5c0540be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d95647-0f59-4d00-b13a-742f0c02ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for o in range(10): print(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fe5d3-2c84-4460-a2a5-24a013adf0c2",
   "metadata": {},
   "source": [
    "Now we want to have a batched sampler than will produce `n` batches of `m` elements each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c189b-e0b0-4f8e-aaeb-893b3a08e51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes iterable and stop value\n",
    "from itertools import islice\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1983ab2-cf6b-4584-9186-f934404315cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15062, 36398, 40185, 30273, 17753]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6c50c-421d-480b-9d99-a1762fbc350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aabe6f-1298-4ea5-b3a7-1b3798e443e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chunkate(it, bs):\n",
    "    for _ in range(0, n, bs):\n",
    "        yield list(islice(it, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb90580-edea-4aee-b7d7-1596c2f4a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, sampler, bs): fc.store_attr()\n",
    "    def __iter__(self): yield from simple_chunkate(iter(self.sampler), self.bs)#fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500aaa8-a248-4ba0-b35d-ab7c324d1c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40763, 23688, 13667, 15060],\n",
       " [47449, 35528, 42501, 37471],\n",
       " [45159, 44332, 15840, 10497],\n",
       " [15046, 37007, 29332, 45454],\n",
       " [398, 37502, 6255, 2235]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3f86b-7d84-4e81-8f15-a9250d4440b2",
   "metadata": {},
   "source": [
    "We can substitute `simple_chunkate` with a more sophisticated version from `fastcore` that is more flexible and takes care of some issues for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ae003-5c6f-456c-a4ea-2e94e8a697ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7e79a-8601-4f70-aa7c-fd73c8c63099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5455, 34485, 45025, 16596],\n",
       " [15412, 49535, 46090, 39437],\n",
       " [2, 34958, 26203, 10019],\n",
       " [28379, 15745, 41260, 11864],\n",
       " [18538, 15395, 31063, 42105]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd6c2a-6796-4ad9-b366-e7bacd55a074",
   "metadata": {},
   "source": [
    "Let's sum up to this point. \n",
    "* `Dataset` is a simple wrapper around xs and ys. It stores those values, has length and get be indexed into to return a tuple.\n",
    "* `Dataloader` yields batches of a given size from a `Dataset`\n",
    "* `Sampler` is a simple sampler that takes a `Dataset` and produces a single index (optionally random) from the dataset. This index can be used to index into a Dataset\n",
    "* `BatchSampler` takes a sampler and a batch size. It yields a batch of indices of given size that can be used to index into a `Dataset`. `BatchSampler` returns when all batches have been yielded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764f43c-58ee-4be2-a0c7-e07d5a238396",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32498a27-afc2-4d5f-929f-3fdf871d8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs): fc.store_attr()\n",
    "    def __iter__(self): yield (self.ds[next(iter(self.batchs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5876809-b949-408c-a036-adb7b1e3ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3cb437-9fd4-4264-bff1-962c7f8fa583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28, 28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd661ccb-0c8a-43c4-8ee7-422109f9a425",
   "metadata": {},
   "source": [
    "Great, it works! Note, that this implementations differs from PyTorch approach, that uses a __collation function__ to decide how to aggregate data from a batch. We can replicate that approach below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780af2db-a26b-474b-b5d6-80361f2ba7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(iter(train_samp)) # on loop over self.batchs (train_samp)\n",
    "p = [train_ds[i] for i in d][0] # self.ds[i] for i in b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500e292-0a3d-4b14-933d-5d1bfd8cc7b0",
   "metadata": {},
   "source": [
    "We get a tuple of tuples and need to collate that in a suitable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ea324-cca7-41c7-9d9e-034d7ece3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b is a tuple\n",
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad29ac-fb7a-48f8-b098-8684a17cccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bde51d-5779-48ef-b93f-d946e5b7cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fdd2a-7e41-44e7-bf9f-208abc0ada97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7, 6, 8, 9, 0, 3, 8, 3, 7, 7, 8, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(next(iter(valid_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0b99b-6088-41c7-be2c-abc1d367efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANeklEQVR4nO3dfchc9ZnG8etSU0xM0GjYmKTRtE/8pxRj1iArG5ZqSXFFiBUsDbikMZAKFVpdZSUrVJRCWLZV8I9IiiHZtWupiV2lKsaGsL5BMb6sxpfGF2I05oUoaIJKN3rvH8/J8qjP+c2TmTNzZnN/P/AwM+eeM+dm9Mo5c35n5ueIEIDj3wltNwBgMAg7kARhB5Ig7EAShB1I4qRBbsw2p/6BPosIj7e8pz277Uts/9n2G7Zv6uW1APSXux1nt32ipJ2Slkh6V9IzkpZFxCuFddizA33Wjz37BZLeiIi3IuIvkn4raWkPrwegj3oJ+xxJ74x5/G617Atsr7K93fb2HrYFoEd9P0EXEeskrZM4jAfa1MuefY+kuWMef71aBmAI9RL2ZySdY/sbtr8m6YeSHmymLQBN6/owPiKO2L5W0qOSTpS0PiJebqwzAI3qeuitq43xmR3ou75cVAPg/w/CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5IY6JTN6M6CBQuK9euuu662NjIyUlx3ypQpxfrq1auL9VNPPbVYf+SRR2prhw4dKq6LZrFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmMV1CEydOrVY3717d7F+2mmnNdhNs/bs2VNbK10fIEmbNm1qup0U6mZx7emiGtu7JB2S9JmkIxGxqJfXA9A/TVxBd1FEHGzgdQD0EZ/ZgSR6DXtI2mL7WdurxnuC7VW2t9ve3uO2APSg18P4xRGxx/ZfSXrM9msR8fjYJ0TEOknrJE7QAW3qac8eEXuq2wOSfi/pgiaaAtC8rsNu+xTb047el/Q9STuaagxAs7oeZ7f9TY3uzaXRjwP/ERG/6LAOh/HjmDZtWrH+8MMPF+vvv/9+be35558vrrtw4cJi/eyzzy7W586dW6xPnjy5trZ///7iuhdeeGGx3mn9rBofZ4+ItySVf1UBwNBg6A1IgrADSRB2IAnCDiRB2IEk+IorejJjxoxi/cYbb+yqJkkrVqwo1jdu3FisZ1U39MaeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYMpm9OTgwfJvjT711FO1tU7j7J2+fss4+7Fhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOjp5Mnz69WF+9enXXrz179uyu18VXsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgST43XgULVhQnqj3vvvuK9bnz59fW9u5c2dx3SVLlhTr77zzTrGeVde/G297ve0DtneMWXa67cdsv17dlq+sANC6iRzGb5B0yZeW3SRpa0ScI2lr9RjAEOsY9oh4XNIHX1q8VNLR3wTaKOnyZtsC0LRur42fGRF7q/v7JM2se6LtVZJWdbkdAA3p+YswERGlE28RsU7SOokTdECbuh162297liRVtweaawlAP3Qb9gclLa/uL5f0QDPtAOiXjuPstu+V9B1JMyTtl/RzSf8p6XeSzpL0tqQfRMSXT+KN91ocxg+Z5cuXF+u33nprsT537txi/ZNPPqmtXXbZZcV1t23bVqxjfHXj7B0/s0fEsprSd3vqCMBAcbkskARhB5Ig7EAShB1IgrADSfBT0seBqVOn1tZuuOGG4ro333xzsX7CCeX9wQcflEdcFy9eXFt77bXXiuuiWezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmPAxs2bKitXXHFFT299qZNm4r1O+64o1hnLH14sGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZz8OjIyM9O21165dW6w//fTTfds2msWeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9OLBly5ba2oIFC/r22lLncfg1a9bU1t57772uekJ3Ou7Zba+3fcD2jjHLbrG9x/YL1d+l/W0TQK8mchi/QdIl4yy/PSLOq/4ebrYtAE3rGPaIeFxSeY4fAEOvlxN019p+sTrMn173JNurbG+3vb2HbQHoUbdhXytpRNJ5kvZK+mXdEyNiXUQsiohFXW4LQAO6CntE7I+IzyLic0m/lnRBs20BaFpXYbc9a8zD70vaUfdcAMPBEVF+gn2vpO9ImiFpv6SfV4/PkxSSdkn6cUTs7bgxu7wxdGXy5Mm1tXvuuae47vnnn1+sn3XWWV31dNS+fftqaytWrCiu++ijj/a07awiwuMt73hRTUQsG2fx3T13BGCguFwWSIKwA0kQdiAJwg4kQdiBJDoOvTW6MYbeBu7kk08u1k86qTwg89FHHzXZzhd8+umnxfr1119frN91111NtnPcqBt6Y88OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo6ic889t1i//fbbi/WLLrqo623v3r27WJ83b17Xr308Y5wdSI6wA0kQdiAJwg4kQdiBJAg7kARhB5JgnH0ITJkypVj/+OOPB9TJsZs+vXbmL0nS+vXra2tLly7tadtz5swp1vfu7fjr5sclxtmB5Ag7kARhB5Ig7EAShB1IgrADSRB2IImOs7iidyMjI8X6k08+Waw/9NBDxfqOHTtqa53GmleuXFmsT5o0qVjvNNY9f/78Yr3kzTffLNazjqN3q+Oe3fZc29tsv2L7Zds/rZafbvsx269Xt+WrKwC0aiKH8Uck/WNEfEvS30j6ie1vSbpJ0taIOEfS1uoxgCHVMewRsTcinqvuH5L0qqQ5kpZK2lg9baOky/vUI4AGHNNndtvzJC2U9CdJMyPi6IemfZJm1qyzStKqHnoE0IAJn423PVXSZkk/i4gvzPYXo9+mGfdLLhGxLiIWRcSinjoF0JMJhd32JI0G/TcRcX+1eL/tWVV9lqQD/WkRQBM6HsbbtqS7Jb0aEb8aU3pQ0nJJa6rbB/rS4XHgyiuvLNbPPPPMYv3qq69usp1jMvqfv14vX5E+fPhwsX7NNdd0/dr4qol8Zv9bSf8g6SXbL1TLVms05L+zvVLS25J+0JcOATSiY9gj4klJdf+8f7fZdgD0C5fLAkkQdiAJwg4kQdiBJAg7kARfcR2AM844o+0W+mbz5s3F+m233VZbO3CgfB3Wvn37uuoJ42PPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMGXzAHT6OeaLL764WL/qqquK9dmzZ9fWPvzww+K6ndx5553F+hNPPFGsHzlypKft49gxZTOQHGEHkiDsQBKEHUiCsANJEHYgCcIOJME4O3CcYZwdSI6wA0kQdiAJwg4kQdiBJAg7kARhB5LoGHbbc21vs/2K7Zdt/7RafovtPbZfqP4u7X+7ALrV8aIa27MkzYqI52xPk/SspMs1Oh/74Yj41wlvjItqgL6ru6hmIvOz75W0t7p/yParkuY02x6Afjumz+y250laKOlP1aJrbb9oe73t6TXrrLK93fb23loF0IsJXxtve6qk/5L0i4i43/ZMSQclhaTbNHqof3WH1+AwHuizusP4CYXd9iRJf5D0aET8apz6PEl/iIhvd3gdwg70WddfhLFtSXdLenVs0KsTd0d9X9KOXpsE0D8TORu/WNITkl6S9Hm1eLWkZZLO0+hh/C5JP65O5pVeiz070Gc9HcY3hbAD/cf32YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0l0/MHJhh2U9PaYxzOqZcNoWHsb1r4keutWk72dXVcY6PfZv7Jxe3tELGqtgYJh7W1Y+5LorVuD6o3DeCAJwg4k0XbY17W8/ZJh7W1Y+5LorVsD6a3Vz+wABqftPTuAASHsQBKthN32Jbb/bPsN2ze10UMd27tsv1RNQ93q/HTVHHoHbO8Ys+x024/Zfr26HXeOvZZ6G4ppvAvTjLf63rU9/fnAP7PbPlHSTklLJL0r6RlJyyLilYE2UsP2LkmLIqL1CzBs/52kw5L+7ejUWrb/RdIHEbGm+odyekT805D0douOcRrvPvVWN834j9Tie9fk9OfdaGPPfoGkNyLirYj4i6TfSlraQh9DLyIel/TBlxYvlbSxur9Ro/+zDFxNb0MhIvZGxHPV/UOSjk4z3up7V+hrINoI+xxJ74x5/K6Ga773kLTF9rO2V7XdzDhmjplma5+kmW02M46O03gP0pemGR+a966b6c97xQm6r1ocEX8t6e8l/aQ6XB1KMfoZbJjGTtdKGtHoHIB7Jf2yzWaqacY3S/pZRHw0ttbmezdOXwN539oI+x5Jc8c8/nq1bChExJ7q9oCk32v0Y8cw2X90Bt3q9kDL/fyfiNgfEZ9FxOeSfq0W37tqmvHNkn4TEfdXi1t/78bra1DvWxthf0bSOba/Yftrkn4o6cEW+vgK26dUJ05k+xRJ39PwTUX9oKTl1f3lkh5osZcvGJZpvOumGVfL713r059HxMD/JF2q0TPyb0r65zZ6qOnrm5L+u/p7ue3eJN2r0cO6/9HouY2Vks6QtFXS65L+KOn0Iert3zU6tfeLGg3WrJZ6W6zRQ/QXJb1Q/V3a9ntX6Gsg7xuXywJJcIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5L4X7rpScZW9kGEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(next(iter(valid_dl)))\n",
    "plt.imshow(xb[0].view(28, 28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cf6fa-0092-4304-9302-0e7d4ef1888b",
   "metadata": {},
   "source": [
    "Notice that to get to the actual values we needed to call `next` twice. This is because the result of the yield is a generator. We can avoid this in two ways: either write and explicit loop or use \n",
    "```python\n",
    "yield from\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d263844-b41a-415e-a0a8-ba39a6713fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        for v in (self.collate_fn(self.ds[i] for i in b) for b in self.batchs):\n",
    "            yield v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db011384-b412-4194-9cf9-d62a5e101b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf72ee-1c1e-4be6-8898-ad6f2e26c937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415f1b5-4375-4eeb-839e-83f85dbe6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82b293-9cf9-43ad-b8f2-e07dfda58e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b0cf3-39f9-4adf-b057-f18e9aaf220d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce550a-2fae-4d83-8765-15449c32fdb2",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb8953-ba85-41b7-a991-04cf863a68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460731a-c79a-49d8-84f9-566962dff7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7762b-2388-48b1-8cfe-1dcc411d7e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5260de6-21a2-421f-8fed-ea4d6a6f5fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a510252-c809-4fd2-879a-6a603fe09b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2e65e-d03e-4326-a834-b2a94c4b7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds, batchs=train_samp, n_workers=1)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ee411-1031-439b-9938-da8d108f3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xb,yb = next(it)\n",
    "#xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fee57-c9bb-421e-b791-ad14ed959e69",
   "metadata": {},
   "source": [
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b742e8f-a5ba-4011-8608-af17a7a4a328",
   "metadata": {},
   "source": [
    "Let's see how everythin we build above works using PyTorch classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3836b0-65c3-4936-852c-15253fb4b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bdf9b-ac59-4bd6-b241-ada7456bdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds),bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfefb45-1e4c-443d-b9ff-69ea9ee65f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50db3c-b019-4bbd-b2e0-a78b93c06b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, accuracy:0.98\n",
      "0.09, accuracy:0.98\n",
      "0.06, accuracy:1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ab475-c273-40dd-926e-1d1f55b6a05a",
   "metadata": {},
   "source": [
    "In PyTorch we can skip creating `train_sampl` and `valid_samp` separately and create them inside the `DataLoader` using `sampler` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1421af9-46fe-48b9-ace5-316ce8c20fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b71bd5-3df5-460e-9127-f67fa5f9c806",
   "metadata": {},
   "source": [
    "PyTorch can also generate RandomSampler / SequentialSampler automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ad6bd-5364-4bd8-993a-03a5f074cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,bs, shuffle=True, collate_fn=collate, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bb2f9-d436-442b-b295-c3fc7ed1c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15, accuracy:0.94\n",
      "0.10, accuracy:0.96\n",
      "0.05, accuracy:1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.06, grad_fn=<NllLossBackward0>), tensor(0.98))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31db6604-800f-4d3f-b137-44dd8822945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(iter(train_samp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1b68f-d41f-4cd8-a2d6-bacf53689c37",
   "metadata": {},
   "source": [
    "Our dataset actually already knows how to sample a batch of indices all at once by indexing directly:\n",
    "\n",
    "```pyton\n",
    "train_ds[[4,6,7]]\n",
    "```\n",
    "That means that we can actually skip the batch_sampler and collate_fn entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b27a3-e269-4087-a1cf-cb8144d48f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d3e68-0e63-4314-96a9-7dd81fd1358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f06896-c0eb-482c-a5e5-df2831593e2e",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3077add-f263-4b0a-ba4f-e39adeb4627e",
   "metadata": {},
   "source": [
    "You **always** should have a validation set in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc5994-698b-4a61-8228-01f42d20f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0., 0., 0.\n",
    "            for xb, yb in valid_dl:\n",
    "                preds = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(preds, yb).item() * n\n",
    "                tot_acc += accuracy(preds, yb).item() * n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33daf8-1b77-478d-a085-51d7d0d02d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, bs, shuffle=True, **kwargs), DataLoader(valid_ds, bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24543d72-ae0d-4447-a6ec-adac7658e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686f08d-45b9-4897-b490-27c927452eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1611832752637565 0.9530000042915344\n",
      "1 0.11640510937198996 0.9665000069141388\n",
      "2 0.10893300825729967 0.9684000074863434\n",
      "3 0.11510496831964702 0.9662000024318695\n",
      "4 0.10246456737630069 0.9707000076770782\n",
      "CPU times: user 1min 25s, sys: 197 ms, total: 1min 26s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%time loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9ab5d-83df-4ed8-b5ad-55223bbddc09",
   "metadata": {},
   "source": [
    "## Export - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f5104-3b72-4b81-ad1c-f537c7a45f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014b0d3-2835-4d09-adc7-6d06aa87becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#from nbdev.export import nb_export\n",
    "#nb_export('04_minibatch_training.ipynb', '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
