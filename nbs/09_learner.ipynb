{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca000c-90ba-4ed4-89a6-97df9919373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef97aa-0983-4143-9d6c-28a03a58562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090cf0f6-1ad1-4126-afb3-10d165ceaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import math, torch, matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from miniai.conv import *\n",
    "\n",
    "from fastprogress import progress_bar, master_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dd64c-b109-45a1-8697-3a1b8e42c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import torchvision.transforms.functional as TF\n",
    "from contextlib import contextmanager\n",
    "from torch import nn, tensor\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "from miniai.datasets import *\n",
    "import logging\n",
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84264e5e-523e-42fa-a1e4-0cbc0543c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=160, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c8a55-2596-4872-9884-f6b118b84636",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed751e6-c462-4562-a961-b3bea46a3bd6",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e951d3-fb8f-4091-bba2-e9a45f19a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9b1dbe9d524ad0aea7927ad0c558b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = 'image', 'label'\n",
    "name = 'fashion_mnist'\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08188e7f-6ca1-4c44-94c3-1dc684deea3a",
   "metadata": {},
   "source": [
    "Grab a single example from Dataset and check its shape. We will be working with flattened images, so we convert PIL to tensor and flatten it out to get 784 (28x28) long tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc797c-5ade-43ed-a9ea-1eece904155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = TF.to_tensor(dsd['train'][0][x])\n",
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb8273-24b3-4207-8ee7-be2c229e0dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(TF.to_tensor(dsd['train'][0][x])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03901-0bbb-4008-ae1e-088b946eeb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transformi(b):\n",
    "    # b is a dictionary of image and label\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8902b-69d6-47ff-834a-dedcb58bb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "tds = dsd.with_transform(transformi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede909a-ae34-4899-94f0-d225749065a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 784]), tensor([8, 0, 4, 0, 5, 8, 3, 8, 3, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove number of workers during debugging\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=4)\n",
    "\n",
    "dt = dls.train\n",
    "xb, yb = next(iter(dt))\n",
    "xb.shape, yb[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728e8ca-eb4e-42c6-81a1-a172f03496ba",
   "metadata": {},
   "source": [
    "Let's remind ourselves how `DataLoaders.from_dd` actually works. \n",
    "\n",
    "```python\n",
    "def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n",
    "        f = collate_dict(dd['train'])\n",
    "        return cls(*get_dls(*dd.values(), bs=batch_size, collate_fn=f, **kwargs))\n",
    "```\n",
    "Let's first deal with the first line of code and `f` function. `f` is an internal collation function that itself returns a function returning collated `x` and `y` values from a given batch. This is how it is done:\n",
    "1. `collate_dict` takes feature names from `dd['train']`: `image` and `label` and puts them into an itemgetter\n",
    "2.  this itemgetter is applied to the result of a `default_collate` on a given Dataset returning a tuple of `x` and `y` values\n",
    "\n",
    "```python\n",
    "def collate_dict(ds):\n",
    "    get = itemgetter(*ds.features) # get x and y values\n",
    "    def _f(b): return get(default_collate(b))\n",
    "    return _f\n",
    "```\n",
    "\n",
    "The second line of code (returning) can be broken down into several parts: call `get_dls` and wrap its return value into `cls`. Let's tackle it one by one.\n",
    "\n",
    "```python\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, bs, shuffle=True, **kwargs), DataLoader(valid_ds, bs*2, **kwargs))\n",
    "```\n",
    "\n",
    "`get_dls` takes a train and valid datasets and turns them into the respective DataLoaders (PyTorch). Our created `collate_dict` function (assigned to `f`) is passed to the DataLoader `__init__` method via `**kwargs`\n",
    "\n",
    "Wrapping the resulting tuple of DataLoaders inside `cls` simply allows us to get them by calling .train and .vaild on our Dataloaders class.\n",
    "\n",
    "```python\n",
    "def __init__(self, *dls): self.train, self.valid = dls[:2]\n",
    "```\n",
    "\n",
    "Now we should fully understand the initial code above. We create dataloaders (train and valid), then we select train dataloader and get one batche of size 1024 from it.\n",
    "\n",
    "```python\n",
    "dls = DataLoaders.from_dd(tds, bs)\n",
    "dt = dls.train\n",
    "xb, yb = next(iter(dt))\n",
    "```\n",
    "During the call to iterator our collation function (`f`) comes in play and merges the 1024 element list of dictionaries into a tuple of `x` and `y` tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0395dc7-534c-423b-81ec-42b35be02a35",
   "metadata": {},
   "source": [
    "Now let's move on to creating our first Learner framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12dbc8-38e8-4c78-8a1d-ebe4d5d59692",
   "metadata": {},
   "source": [
    "##  Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3fdd3-e566-4a8e-b873-fe45afb9e9b0",
   "metadata": {},
   "source": [
    "First we create a simplified learner that still has some nice structure to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af106857-fc8c-4f83-8caa-50e976f5fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, loss_func, lr, opt_func=optim.SGD): fc.store_attr()\n",
    "    \n",
    "    def one_batch(self):\n",
    "        self.xb, self.yb = to_device(self.batch)\n",
    "        self.preds = self.model(self.xb)\n",
    "        self.loss = self.loss_func(self.preds, self.yb)\n",
    "        if self.model.training:\n",
    "            self.loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "        with torch.no_grad(): self.calc_stats()\n",
    "        \n",
    "    def calc_stats(self):\n",
    "        acc = (self.preds.argmax(dim=-1)==self.yb).float().sum()\n",
    "        self.accs.append(acc)\n",
    "        n = len(self.xb)\n",
    "        self.losses.append(self.loss * n)\n",
    "        self.ns.append(n)\n",
    "        \n",
    "        \n",
    "    def one_epoch(self, train):\n",
    "        self.model.training = train\n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for _, self.batch in enumerate(dl): self.one_batch()\n",
    "        n = sum(self.ns)\n",
    "        print(self.epoch, self.model.training, \n",
    "              sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
    "        \n",
    "        \n",
    "    def fit(self, n_epochs):\n",
    "        self.accs, self.losses, self.ns = [], [], []\n",
    "        self.model.to(def_device)\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        self.n_epochs = n_epochs\n",
    "        for self.epoch in range(n_epochs):\n",
    "            self.one_epoch(True)\n",
    "            with torch.no_grad(): self.one_epoch(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255723b-43bb-4f29-aa59-6f672e91862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, nh = 28*28, 50\n",
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c865a6b-d8f3-4fbb-a37a-e9409d213237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.154941015625 0.6162166666666666\n",
      "0 False 1.10222109375 0.6292\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(model, dls, F.cross_entropy, lr=0.2)\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54458635-6ddd-4990-bbfa-94bebc343daa",
   "metadata": {},
   "source": [
    "## Basic Callbacks Learner "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0057b-50e6-4fee-a1e3-8aa50de9619e",
   "metadata": {},
   "source": [
    "Now let's improve greatly upon our previus iteration and add Callbacks to our Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2803c9-5867-46df-acc0-730b582a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelEpochException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb20c4f-bf71-48f5-9c16-5d91ce3fadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Callback: order = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660fe97-cfca-40f0-9cd8-2fb30cef6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def run_cbs(cbs, method_nm, learn=None):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        #?\n",
    "        if method is not None: method(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f0625-2f15-4524-99aa-30fa59b510a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompletionCB(Callback):\n",
    "    def before_fit(self, learn): self.count = 0\n",
    "    def after_batch(self, learn): self.count += 1\n",
    "    def after_fit(self, learn): print(f'Completed {self.count} batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c51de-66d3-4937-a4bf-1f5e4f2bdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1 batches\n"
     ]
    }
   ],
   "source": [
    "cbs = [CompletionCB()]\n",
    "run_cbs(cbs, 'before_fit')\n",
    "run_cbs(cbs, 'after_batch')\n",
    "run_cbs(cbs, 'after_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70b56e-6baa-43c5-81e9-399131f93066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467b6f0-dfd6-40d1-b884-107ef8bb1b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59593a-3bf3-48d0-a819-3f0c10dedf10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb81d3-5024-4b6f-9653-cc044021ee67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f58861-0f3f-43b8-87e0-c3863a6f65ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7d1c8-2390-4448-bc36-e8b5cffbabe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d5de1-b54a-45d3-9df7-002586d5f679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2855e4c-cbd0-48cd-8db0-95f4cd7dfbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7231b100-5a6d-4ddd-a6ef-91234e7f0542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11f161-df22-456a-bee4-4c93c2656201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e5685-4018-49fa-9d1d-536f613cb7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
